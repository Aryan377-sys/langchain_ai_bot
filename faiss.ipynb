{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How FAISS Works\n",
    "\n",
    "- #### FAISS provides various methods to store and retrieve embeddings efficiently. The most common technique is IndexFlatL2, which performs a brute-force L2 (Euclidean) distance search efficiently.\n",
    "\n",
    "#### ðŸ‘‰ Basic Steps:\n",
    "\n",
    "- #### Convert Text into Embeddings:\n",
    "    - #### Sentences like \"I love pizza\" are converted into vectors using an embedding model (e.g., OpenAI's text-embedding-ada-002 or SentenceTransformers from Hugging Face).\n",
    "    - #### Example: \"I love pizza\" â†’ [0.4, 0.6, 0.1, 0.8]\n",
    "\n",
    "- #### Store Embeddings in FAISS\n",
    "    - #### FAISS stores these embeddings in a searchable index.\n",
    "\n",
    "- #### Query Search\n",
    "    ##### When you search with \"Pizza is amazing\", its embedding is computed and compared against stored embeddings using a distance metric (like cosine similarity or Euclidean distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu   # or faiss-gpu if you have a GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Example document embeddings (each row represents a sentence embedding)\n",
    "document_vectors = np.array([\n",
    "    [0.1, 0.8, 0.3],  # Embedding for \"I love pizza\"\n",
    "    [0.5, 0.2, 0.9],  # Embedding for \"Pizza is my favorite\"\n",
    "    [0.3, 0.7, 0.2]   # Embedding for another document\n",
    "]).astype(\"float32\")\n",
    "\n",
    "# Create FAISS index using L2 distance\n",
    "index = faiss.IndexFlatL2(3)  # 3D vector space\n",
    "index.add(document_vectors)  # Add documents to index\n",
    "\n",
    "# Query vector (embedding for \"I enjoy eating pizza\")\n",
    "query_vector = np.array([[0.2, 0.75, 0.25]]).astype(\"float32\")\n",
    "\n",
    "# Search for the closest document\n",
    "_, indices = index.search(query_vector, 1)  # Find 1 closest match\n",
    "\n",
    "print(f\"Most similar document index: {indices[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's work with a basic Q/A dataset to build a basic Q/A chatbot prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_queries = {\n",
    "\"How do I place an order?\": \"To place an order, browse products, add them to your cart, and proceed to checkout. Enter your shipping and payment details and confirm the order.\",\n",
    "\n",
    "\"Can I modify my order after placing it?\": \"You can modify your order within 30 minutes of placing it by going to 'My Orders' and selecting 'Edit Order'. After this period, modifications may not be possible.\",\n",
    "\n",
    "\"How do I cancel my order?\": \"Go to 'My Orders', select the order, and click 'Cancel'. If the order has already been shipped, you may need to request a return instead.\",\n",
    "\n",
    "\"What payment methods do you accept?\": \"We accept credit/debit cards, UPI, net banking, PayPal, and cash on delivery (COD) for eligible orders.\",\n",
    "\n",
    "\"How do I track my order?\": \"You can track your order by clicking on 'My Orders' and selecting 'Track Order'. Youâ€™ll receive a tracking link via email/SMS once itâ€™s shipped.\",\n",
    "\n",
    "\"What is your return policy?\": \"You can return products within 7 days of delivery if they are unused and in original packaging. Refunds are processed within 5-7 business days.\",\n",
    "\n",
    "\"How do I initiate a return?\": \"Go to 'My Orders', select the order, and click on 'Return'. Follow the instructions to schedule a pickup or drop-off.\",\n",
    "\n",
    "\"When will I get my refund?\": \"Refunds for prepaid orders are processed within 5-7 business days after the return is approved. COD orders receive a refund via bank transfer or store credit.\",\n",
    "\n",
    "\"Why is my order delayed?\": \"Order delays can happen due to high demand, weather conditions, or courier service issues. Check 'My Orders' for real-time tracking updates.\",\n",
    "\n",
    "\"Do you offer express delivery?\": \"Yes, we offer express delivery in select locations for an additional fee. Choose 'Express Shipping' at checkout if available.\",\n",
    "\n",
    "\"Can I change my delivery address?\": \"You can change the delivery address before the order is shipped by going to 'My Orders' and selecting 'Edit Address'. Once shipped, address changes are not possible.\",\n",
    "\n",
    "\"What should I do if I receive a damaged product?\": \"If you receive a damaged product, report it within 48 hours by visiting 'My Orders' and selecting 'Report Issue'. You may be eligible for a replacement or refund.\",\n",
    "\n",
    "\"Do you provide international shipping?\": \"Currently, we ship only within [Country Name]. International shipping options will be available soon.\",\n",
    "\n",
    "\"How do I apply a discount code?\": \"Enter your discount code at checkout in the 'Apply Coupon' section. If valid, the discount will be applied to your total amount.\",\n",
    "\n",
    "\"Why was my payment declined?\": \"Payments may be declined due to incorrect details, insufficient funds, or bank restrictions. Try using another payment method or contact your bank.\",\n",
    "\n",
    "\"Can I buy now and pay later?\": \"Yes, we offer 'Buy Now, Pay Later' options through [BNPL Provider]. Choose this option at checkout to pay in installments.\",\n",
    "\n",
    "\"How can I contact customer support?\": \"You can reach our customer support via email at support@example.com, live chat on our website, or by calling our helpline at [phone number].\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[i for i in customer_queries.keys()] # Get all the keys from the dictionary(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the maximum length of sentences among all in questions\n",
    "- ## helpful to get padding of vector embedding (better for visualizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "t = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenized_sentences = [t.tokenize(se) for se in questions]\n",
    "max_length = max(len(tokens) for tokens in tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode questions to vector-vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: [[-0.00525269 -0.0027741   0.00439012 ...  0.05966287 -0.00959073\n",
      "  -0.03116936]\n",
      " [-0.01255482  0.02828169  0.03745556 ... -0.05449416  0.02443732\n",
      "  -0.05462256]\n",
      " [-0.0098854   0.05941395  0.07196155 ... -0.00860798 -0.041535\n",
      "  -0.06529609]\n",
      " ...\n",
      " [ 0.03389934  0.11285317  0.09194537 ... -0.0623031  -0.03781408\n",
      "  -0.02075073]\n",
      " [-0.01548825 -0.00544532 -0.00193917 ... -0.09687741  0.07747193\n",
      "  -0.0597066 ]\n",
      " [-0.06125683  0.0057992   0.05149605 ... -0.00036161 -0.00158965\n",
      "  -0.00253615]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# You can do it using library \n",
    "# Embeddings = model.encode(questions, \n",
    "#                           convert_to_numpy=True,  # Get NumPy output\n",
    "#                           normalize_embeddings=True,  # Normalize the output\n",
    "#                           show_progress_bar=True)  # Show progress\n",
    "\n",
    "## If you want to do it manually\n",
    "encoded_questions = t(questions, \n",
    "                           padding='max_length',  \n",
    "                           truncation=True, \n",
    "                           max_length=max_length, \n",
    "                           return_tensors=\"pt\")  \n",
    "print(\"Sentence embeddings:\", embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide questions from user and finding similarity with given questions in our dataset to fetch answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching question from user and encoding it in vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101,  2215, 25416,  8630,   102,     0,     0,     0,     0,\n",
       "            0,     0]]), 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_questions=input(\"Enter Your question: \") # Get the user question\n",
    "encoded_user_questions= t(user_questions, \n",
    "                           padding='max_length',  \n",
    "                           truncation=True, \n",
    "                           max_length=max_length, \n",
    "                           return_tensors=\"np\")   # Encode the user question\n",
    "encoded_user_questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: np.str_('input_ids')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Compute similarity\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_user_questions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoded_questions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine Similarity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sohanpython/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/sohanpython/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:1741\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1741\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/sohanpython/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:200\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    190\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    191\u001b[0m         X,\n\u001b[1;32m    192\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    210\u001b[0m         Y,\n\u001b[1;32m    211\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[0;32m~/sohanpython/lib/python3.13/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/sohanpython/lib/python3.13/site-packages/sklearn/utils/_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: np.str_('input_ids')"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute similarity\n",
    "similarity = cosine_similarity(encoded_user_questions,encoded_questions)\n",
    "print(f\"Cosine Similarity: {similarity[0][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- How FAISS Works\n",
    "\n",
    "FAISS provides various methods to store and retrieve embeddings efficiently. The most common technique is IndexFlatL2, which performs a brute-force L2 (Euclidean) distance search efficiently.\n",
    "\n",
    "ðŸ‘‰ Basic Steps:\n",
    "\n",
    "    Convert Text into Embeddings\n",
    "        Sentences like \"I love pizza\" are converted into vectors using an embedding model (e.g., OpenAI's text-embedding-ada-002 or SentenceTransformers from Hugging Face).\n",
    "        Example: \"I love pizza\" â†’ [0.4, 0.6, 0.1, 0.8]\n",
    "\n",
    "    Store Embeddings in FAISS\n",
    "        FAISS stores these embeddings in a searchable index.\n",
    "\n",
    "    Query Search\n",
    "        When you search with \"Pizza is amazing\", its embedding is computed and compared against stored embeddings using a distance metric (like cosine similarity or Euclidean distance). -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sohanpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
