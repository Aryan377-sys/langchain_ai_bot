{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How FAISS Works\n",
    "\n",
    "- #### FAISS provides various methods to store and retrieve embeddings efficiently. The most common technique is IndexFlatL2, which performs a brute-force L2 (Euclidean) distance search efficiently.\n",
    "\n",
    "#### ðŸ‘‰ Basic Steps:\n",
    "\n",
    "- #### Convert Text into Embeddings:\n",
    "    - #### Sentences like \"I love pizza\" are converted into vectors using an embedding model (e.g., OpenAI's text-embedding-ada-002 or SentenceTransformers from Hugging Face).\n",
    "    - #### Example: \"I love pizza\" â†’ [0.4, 0.6, 0.1, 0.8]\n",
    "\n",
    "- #### Store Embeddings in FAISS\n",
    "    - #### FAISS stores these embeddings in a searchable index.\n",
    "\n",
    "- #### Query Search\n",
    "    ##### When you search with \"Pizza is amazing\", its embedding is computed and compared against stored embeddings using a distance metric (like cosine similarity or Euclidean distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu   # or faiss-gpu if you have a GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document index: 2\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Example document embeddings (each row represents a sentence embedding)\n",
    "document_vectors = np.array([\n",
    "    [0.1, 0.8, 0.3],  # Embedding for \"I love pizza\"\n",
    "    [0.5, 0.2, 0.9],  # Embedding for \"Pizza is my favorite\"\n",
    "    [0.3, 0.7, 0.2]   # Embedding for another document\n",
    "]).astype(\"float32\")\n",
    "\n",
    "# Create FAISS index using L2 distance\n",
    "index = faiss.IndexFlatL2(3)  # 3D vector space\n",
    "index.add(document_vectors)  # Add documents to index\n",
    "\n",
    "# Query vector (embedding for \"I enjoy eating pizza\")\n",
    "query_vector = np.array([[0.2, 0.75, 0.25]]).astype(\"float32\")\n",
    "\n",
    "# Search for the closest document\n",
    "_, indices = index.search(query_vector, 1)  # Find 1 closest match\n",
    "\n",
    "print(f\"Most similar document index: {indices[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's work with a basic Q/A dataset to build a basic Q/A chatbot prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_queries = {\n",
    "\"How do I place an order?\": \"To place an order, browse products, add them to your cart, and proceed to checkout. Enter your shipping and payment details and confirm the order.\",\n",
    "\n",
    "\"Can I modify my order after placing it?\": \"You can modify your order within 30 minutes of placing it by going to 'My Orders' and selecting 'Edit Order'. After this period, modifications may not be possible.\",\n",
    "\n",
    "\"How do I cancel my order?\": \"Go to 'My Orders', select the order, and click 'Cancel'. If the order has already been shipped, you may need to request a return instead.\",\n",
    "\n",
    "\"What payment methods do you accept?\": \"We accept credit/debit cards, UPI, net banking, PayPal, and cash on delivery (COD) for eligible orders.\",\n",
    "\n",
    "\"How do I track my order?\": \"You can track your order by clicking on 'My Orders' and selecting 'Track Order'. Youâ€™ll receive a tracking link via email/SMS once itâ€™s shipped.\",\n",
    "\n",
    "\"What is your return policy?\": \"You can return products within 7 days of delivery if they are unused and in original packaging. Refunds are processed within 5-7 business days.\",\n",
    "\n",
    "\"How do I initiate a return?\": \"Go to 'My Orders', select the order, and click on 'Return'. Follow the instructions to schedule a pickup or drop-off.\",\n",
    "\n",
    "\"When will I get my refund?\": \"Refunds for prepaid orders are processed within 5-7 business days after the return is approved. COD orders receive a refund via bank transfer or store credit.\",\n",
    "\n",
    "\"Why is my order delayed?\": \"Order delays can happen due to high demand, weather conditions, or courier service issues. Check 'My Orders' for real-time tracking updates.\",\n",
    "\n",
    "\"Do you offer express delivery?\": \"Yes, we offer express delivery in select locations for an additional fee. Choose 'Express Shipping' at checkout if available.\",\n",
    "\n",
    "\"Can I change my delivery address?\": \"You can change the delivery address before the order is shipped by going to 'My Orders' and selecting 'Edit Address'. Once shipped, address changes are not possible.\",\n",
    "\n",
    "\"What should I do if I receive a damaged product?\": \"If you receive a damaged product, report it within 48 hours by visiting 'My Orders' and selecting 'Report Issue'. You may be eligible for a replacement or refund.\",\n",
    "\n",
    "\"Do you provide international shipping?\": \"Currently, we ship only within [Country Name]. International shipping options will be available soon.\",\n",
    "\n",
    "\"How do I apply a discount code?\": \"Enter your discount code at checkout in the 'Apply Coupon' section. If valid, the discount will be applied to your total amount.\",\n",
    "\n",
    "\"Why was my payment declined?\": \"Payments may be declined due to incorrect details, insufficient funds, or bank restrictions. Try using another payment method or contact your bank.\",\n",
    "\n",
    "\"Can I buy now and pay later?\": \"Yes, we offer 'Buy Now, Pay Later' options through [BNPL Provider]. Choose this option at checkout to pay in installments.\",\n",
    "\n",
    "\"How can I contact customer support?\": \"You can reach our customer support via email at support@example.com, live chat on our website, or by calling our helpline at [phone number].\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[i for i in customer_queries.keys()] # Get all the keys from the dictionary(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the maximum length of sentences among all in questions\n",
    "- ## helpful to get padding of vector embedding (better for visualizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "t = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenized_sentences = [t.tokenize(se) for se in questions]\n",
    "max_length = max(len(tokens) for tokens in tokenized_sentences)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode questions to vector-vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/sohanx1/sohanpython/lib/python3.13/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: setuptools in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sohanx1/sohanpython/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00525269, -0.0027741 ,  0.00439012, ...,  0.05966287,\n",
       "        -0.00959073, -0.03116936],\n",
       "       [-0.01255482,  0.02828169,  0.03745556, ..., -0.05449416,\n",
       "         0.02443732, -0.05462256],\n",
       "       [-0.0098854 ,  0.05941395,  0.07196155, ..., -0.00860798,\n",
       "        -0.041535  , -0.06529609],\n",
       "       ...,\n",
       "       [ 0.03389934,  0.11285317,  0.09194537, ..., -0.0623031 ,\n",
       "        -0.03781408, -0.02075073],\n",
       "       [-0.01548825, -0.00544532, -0.00193917, ..., -0.09687741,\n",
       "         0.07747193, -0.0597066 ],\n",
       "       [-0.06125683,  0.0057992 ,  0.05149605, ..., -0.00036161,\n",
       "        -0.00158965, -0.00253615]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# You can do it using library \n",
    "# Embeddings = model.encode(questions, \n",
    "#                           convert_to_numpy=True,  # Get NumPy output\n",
    "#                           normalize_embeddings=True,  # Normalize the output\n",
    "#                             show_progress_bar=True)  # Show progress\n",
    "\n",
    "## If you want to do it manually\n",
    "encoded_questions = model.encode(questions, \n",
    "                           convert_to_numpy=True, \n",
    "                            normalize_embeddings=True ) # Normalize for better similarity (some tokens might have higher value commpared to others in vector space so we normalize it)\n",
    "encoded_questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide questions from user and finding similarity with given questions in our dataset to fetch answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching question from user and encoding it in vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.46011809e-02, -6.28258428e-03,  2.81015523e-02,\n",
       "         2.24318001e-02,  7.64028952e-02, -4.33388818e-03,\n",
       "         5.30833527e-02,  2.31589153e-02,  3.49312462e-02,\n",
       "         4.59228940e-02, -2.90395524e-02, -1.25194266e-01,\n",
       "        -3.37083973e-02, -7.53579959e-02, -1.09357804e-01,\n",
       "        -4.03210036e-02,  1.25522958e-03,  7.84120709e-02,\n",
       "        -5.64449877e-02,  2.99849045e-02,  4.54625441e-03,\n",
       "         2.30254494e-02, -1.16831055e-02,  6.63108751e-03,\n",
       "        -3.12581612e-03,  3.77187952e-02, -7.64694512e-02,\n",
       "         1.56072723e-02, -7.80703649e-02, -5.33086471e-02,\n",
       "         7.63645992e-02,  3.49485613e-02,  2.12562867e-02,\n",
       "        -3.98536175e-02,  2.39744820e-02, -3.10086440e-02,\n",
       "        -2.49487031e-02, -2.03769952e-02, -2.03674636e-03,\n",
       "        -9.06769093e-03, -5.37639894e-02, -5.40074073e-02,\n",
       "         1.99646000e-02,  3.96168008e-02,  1.59770176e-02,\n",
       "         4.34888043e-02, -3.15230154e-02,  4.81897146e-02,\n",
       "         1.11820586e-01,  6.01163022e-02, -2.27848114e-03,\n",
       "        -7.30937570e-02, -4.19733152e-02,  2.31115334e-02,\n",
       "         6.28473982e-02,  3.07829957e-02,  3.32529470e-02,\n",
       "         5.94232380e-02, -2.65550613e-02, -2.24196147e-02,\n",
       "         1.24270776e-02, -1.11310244e-01, -3.79149877e-02,\n",
       "        -4.76695746e-02, -2.79317480e-02,  5.42291850e-02,\n",
       "        -4.82917801e-02,  1.44083668e-02,  3.62175964e-02,\n",
       "         1.25945359e-03,  5.90035655e-02, -6.99736830e-03,\n",
       "         1.76104810e-02, -1.58826709e-02,  3.43713276e-02,\n",
       "         8.41198564e-02, -2.21015722e-03,  3.50093795e-03,\n",
       "        -2.00852863e-02,  9.51831117e-02, -7.92009160e-02,\n",
       "        -1.16805010e-01, -2.62565725e-02,  1.28537463e-02,\n",
       "         9.46006998e-02, -6.16415069e-02,  2.80802809e-02,\n",
       "        -8.78853817e-03,  5.39261550e-02, -1.22592850e-02,\n",
       "         5.20167351e-02, -2.42149774e-02,  6.62164614e-02,\n",
       "        -5.14099449e-02, -5.11662140e-02,  1.09474640e-02,\n",
       "         1.17163137e-02, -4.43201326e-02, -1.45032769e-02,\n",
       "         1.36077181e-01,  3.28193903e-02,  5.25807776e-02,\n",
       "         1.25346752e-02, -4.76840585e-02, -3.22185410e-03,\n",
       "         5.36972983e-03,  2.77027264e-02,  6.47287294e-02,\n",
       "        -2.33188691e-03, -1.75673738e-02, -6.03493378e-02,\n",
       "        -3.24505866e-02, -4.04799841e-02,  2.07192488e-02,\n",
       "         5.16373292e-02,  1.65980607e-02, -6.57386333e-02,\n",
       "        -3.31762992e-02,  4.19759490e-02, -1.03935085e-01,\n",
       "         1.07221445e-02,  1.13889150e-01, -5.77344485e-02,\n",
       "         7.39102438e-02, -2.10799575e-02, -1.37801394e-01,\n",
       "         3.04781366e-02, -3.54022091e-33, -1.67929009e-02,\n",
       "         8.86261463e-02,  1.33552253e-02, -1.08196158e-02,\n",
       "         6.37370050e-02, -1.86160486e-02,  2.25470904e-02,\n",
       "         1.08315898e-02, -1.35319410e-02, -3.82633385e-04,\n",
       "         5.00413869e-03,  1.07784525e-01, -3.98632623e-02,\n",
       "         1.51022291e-02, -1.54740438e-01,  2.83060279e-02,\n",
       "        -5.08808233e-02,  2.54313573e-02, -3.58064920e-02,\n",
       "        -1.18916966e-02, -7.75840506e-03,  5.60462940e-03,\n",
       "         1.52125433e-02, -2.82412879e-02,  3.22011951e-03,\n",
       "        -1.77759510e-02, -6.67012557e-02, -4.60296171e-03,\n",
       "         6.92401603e-02, -4.28786175e-03,  1.46012465e-02,\n",
       "        -5.43488376e-03,  6.28599524e-02, -8.88351277e-02,\n",
       "        -5.53551763e-02, -5.36989532e-02,  4.31675054e-02,\n",
       "        -3.02648302e-02, -5.31003661e-02, -4.05798033e-02,\n",
       "         2.94230953e-02,  3.24887224e-02, -6.14550300e-02,\n",
       "         1.42087899e-02,  1.43147791e-02, -4.13319282e-02,\n",
       "         4.52129990e-02,  2.40737554e-02,  8.53519328e-03,\n",
       "         3.27266194e-02,  9.73468181e-03,  1.05473399e-01,\n",
       "        -6.40627295e-02, -1.51614128e-02, -2.01361775e-02,\n",
       "        -2.48396769e-02,  2.09240429e-02, -1.47534860e-02,\n",
       "         1.53348623e-02, -5.24823787e-03,  4.86282259e-02,\n",
       "        -7.83047602e-02, -7.98141062e-02,  4.53000516e-02,\n",
       "        -1.45272538e-01, -7.33473152e-02,  5.46607971e-02,\n",
       "         1.84611522e-03, -6.82145879e-02,  1.63238328e-02,\n",
       "        -1.54163141e-03, -1.78111512e-02,  5.23981713e-02,\n",
       "        -3.86510119e-02, -4.50942060e-03, -9.98084992e-03,\n",
       "        -8.37110430e-02, -3.44311744e-02, -7.81718567e-02,\n",
       "        -7.39230216e-02,  5.49271144e-02, -6.99085146e-02,\n",
       "        -1.80844367e-02,  3.63047794e-02,  1.25003844e-01,\n",
       "        -5.94742736e-03,  9.47524793e-03, -3.97450887e-02,\n",
       "         2.21511014e-02, -9.05855447e-02, -1.17928647e-01,\n",
       "        -3.00751533e-02,  9.91906738e-04, -9.64904111e-03,\n",
       "         6.79857060e-02,  2.60895939e-33,  2.19773222e-03,\n",
       "        -3.56008410e-02, -3.19218449e-02, -2.38801688e-02,\n",
       "         2.22564507e-02,  4.60860133e-02,  8.87455232e-03,\n",
       "         6.49266765e-02,  5.69737032e-02,  6.84325546e-02,\n",
       "        -1.85613781e-02, -3.82490195e-02,  1.15475044e-01,\n",
       "         1.97004378e-02,  2.22152025e-02, -4.96344306e-02,\n",
       "         5.17142452e-02,  3.83998342e-02,  3.91512997e-02,\n",
       "        -3.86723354e-02,  1.63066390e-04,  4.91089448e-02,\n",
       "         7.82667696e-02,  5.45349568e-02, -6.72900379e-02,\n",
       "         4.01567742e-02,  3.14129815e-02, -1.68015528e-02,\n",
       "        -2.08315775e-02,  3.75536345e-02,  9.50329155e-02,\n",
       "        -8.52984637e-02, -8.31570178e-02,  3.48764323e-02,\n",
       "         5.78786619e-02, -5.66362403e-02, -9.16580297e-03,\n",
       "         7.66911805e-02, -4.87185866e-02,  3.71928886e-02,\n",
       "         6.72887266e-02,  2.52033677e-02,  3.26458476e-02,\n",
       "         5.46977557e-02,  1.33896843e-02,  3.84307317e-02,\n",
       "         2.45642904e-02, -5.33452965e-02,  5.91164567e-02,\n",
       "         2.24770065e-02, -4.93481420e-02,  3.13312523e-02,\n",
       "         2.21648701e-02,  2.25493051e-02, -2.01505478e-02,\n",
       "        -4.41638008e-02,  9.87653993e-03, -2.47465186e-02,\n",
       "         1.84936021e-02, -4.17780830e-03, -2.91278921e-02,\n",
       "        -1.68067012e-02, -1.03595905e-01,  1.28394486e-02,\n",
       "         5.32056205e-04,  7.29102502e-03,  5.46817742e-02,\n",
       "        -1.06144674e-01,  3.37343998e-02,  5.29668368e-02,\n",
       "        -2.93969689e-03,  1.86768714e-02, -1.85895115e-02,\n",
       "         1.64777711e-02,  8.94095227e-02,  8.32431242e-02,\n",
       "         9.28127789e-04,  1.58978198e-02,  1.52620231e-03,\n",
       "         6.92076907e-02,  9.93358940e-02,  5.65429358e-03,\n",
       "         3.85346115e-02,  6.46508634e-02,  2.51023248e-02,\n",
       "        -1.30181462e-01,  6.20646253e-02, -3.88304554e-02,\n",
       "         3.64679694e-02, -4.24186774e-02, -1.55708781e-02,\n",
       "        -5.58731034e-02, -2.41854247e-02,  8.17681849e-02,\n",
       "         1.58263724e-02, -1.75670785e-08, -3.29451114e-02,\n",
       "         3.78447771e-02,  9.93897766e-02,  6.48161694e-02,\n",
       "         7.29574030e-03, -2.39588809e-03, -2.57026628e-02,\n",
       "         3.23243402e-02, -4.96860640e-03, -1.28435679e-02,\n",
       "         8.20247922e-03,  3.94464284e-03,  2.20362078e-02,\n",
       "         1.25944940e-02, -1.85554381e-02,  1.70223638e-02,\n",
       "        -3.63333188e-02,  4.35462454e-03,  4.23293933e-02,\n",
       "         2.42636781e-02, -7.09837005e-02,  2.64623296e-02,\n",
       "         5.59225157e-02,  1.08349137e-02,  8.11143965e-03,\n",
       "         4.69529293e-02,  7.10533485e-02,  1.49180830e-01,\n",
       "         3.05532403e-02, -6.23200834e-03, -3.77267376e-02,\n",
       "         3.97792831e-02,  6.41006380e-02, -2.88260859e-02,\n",
       "        -1.85564980e-01, -8.21687877e-02, -7.10879639e-02,\n",
       "         4.62303013e-02,  4.80470993e-02, -3.82105894e-02,\n",
       "         1.63570195e-02,  2.02860287e-03,  2.85632927e-02,\n",
       "        -3.12516727e-02,  2.69685090e-02, -4.69365885e-04,\n",
       "        -1.41264256e-02, -9.73107666e-02,  5.90495905e-03,\n",
       "         8.54172278e-03, -4.23743986e-02, -8.98647904e-02,\n",
       "         7.30555132e-02, -1.11759407e-03,  4.37674820e-02,\n",
       "        -2.76903715e-02, -3.64422724e-02,  5.63287772e-02,\n",
       "        -6.96544796e-02,  2.31368449e-02,  7.14967772e-02,\n",
       "        -6.55922154e-03, -2.21248157e-02, -4.17605899e-02]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_questions=input(\"Enter Your question: \") # Get the user question\n",
    "encoded_user_questions= model.encode(user_questions, \n",
    "                           padding='max_length',  \n",
    "                           truncation=True, \n",
    "                           max_length=max_length, \n",
    "                           return_tensors=\"pt\").reshape(1,-1)   # cosine_similarity() requires 2D input. So, reshaping it to 2D\n",
    "encoded_user_questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.17\n",
      "Question that matches it is : When will I get my refund?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute similarity with all   query in our dataset\n",
    "similarity = cosine_similarity(encoded_user_questions,encoded_questions)\n",
    "most_similar_idx = np.argmax(similarity)\n",
    "print(f\"Cosine Similarity: {similarity[0][0]:.2f}\")\n",
    "print(f'Question that matches it is : {questions[most_similar_idx]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- How FAISS Works\n",
    "\n",
    "FAISS provides various methods to store and retrieve embeddings efficiently. The most common technique is IndexFlatL2, which performs a brute-force L2 (Euclidean) distance search efficiently.\n",
    "\n",
    "ðŸ‘‰ Basic Steps:\n",
    "\n",
    "    Convert Text into Embeddings\n",
    "        Sentences like \"I love pizza\" are converted into vectors using an embedding model (e.g., OpenAI's text-embedding-ada-002 or SentenceTransformers from Hugging Face).\n",
    "        Example: \"I love pizza\" â†’ [0.4, 0.6, 0.1, 0.8]\n",
    "\n",
    "    Store Embeddings in FAISS\n",
    "        FAISS stores these embeddings in a searchable index.\n",
    "\n",
    "    Query Search\n",
    "        When you search with \"Pizza is amazing\", its embedding is computed and compared against stored embeddings using a distance metric (like cosine similarity or Euclidean distance). -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sohanpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
